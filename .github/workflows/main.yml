name: Daily Job Scraper

on:
  schedule:
    - cron: "30 1 * * 0" # Sunday at 1:30 AM UTC (7:00 AM IST)
    - cron: "30 1 * * 3" # Wednesday at 1:30 AM UTC (7:00 AM IST)
    - cron: "30 1 * * 5" # Friday at 1:30 AM UTC (7:00 AM IST)
  workflow_dispatch: # Allows manual trigger

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "20"

      - name: Install dependencies
        run: |
          npm install
          npm install puppeteer-core

      - name: Install Chromium
        run: |
          sudo apt-get update
          sudo apt-get install -y wget unzip chromium-browser

      - name: Run the script
        id: scrape
        run: |
          node index.js
        env:
          CHROME_EXECUTABLE_PATH: /usr/bin/chromium-browser
        continue-on-error: true # Continue even if the script fails

      - name: Send Email
        id: send-email
        run: |
          node sendEmail.js
        env:
          EMAIL_USER: ${{ secrets.EMAIL_USER }}
          EMAIL_PASS: ${{ secrets.EMAIL_PASS }}
          RECIPIENT_EMAIL: ${{ secrets.RECIPIENT_EMAIL }}
        continue-on-error: true # Continue even if sending email fails

      - name: Clean up
        run: |
          rm -f jobs.xlsx || echo "No jobs.xlsx file to delete"
        if: always() # Ensure this step runs regardless of previous step results

      - name: Notify if Script Failed
        if: failure() # Only run if the previous steps failed
        run: |
          echo "Script failed or email could not be sent. Check the logs for details."
